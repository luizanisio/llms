# -*- coding: utf-8 -*-
"""
Compara√ß√£o de extra√ß√µes de espelhos usando m√∫ltiplas m√©tricas de similaridade.

Autor: Luiz An√≠sio
Fonte: https://github.com/luizanisio/llms/tree/main/experimentos/agentes-esp-acordao
Data: 14/11/2025

Descri√ß√£o:
-----------
Compara espelhos extra√≠dos por diferentes abordagens (RAW, base, agentes) e modelos
(GPT-5, Gemma-3 12b/27b) usando BERTScore, ROUGE-L, ROUGE-2 e Levenshtein.
Seleciona m√©tricas apropriadas para cada tipo de campo conforme filosofia documentada.

IMPORTANTE:
-----------
Os imports e configura√ß√µes pesadas s√£o isolados em fun√ß√µes/blocos condicionais para
evitar que os processos workers do BERTScore reimportem configura√ß√µes desnecess√°rias.
Quando multiprocessing usa 'spawn', cada processo filho reimporta o m√≥dulo principal.
"""

import os
import sys

# Imports leves que n√£o causam problemas com multiprocessing
import regex as re

# ============================================================================
# PROTE√á√ÉO CONTRA REIMPORTA√á√ÉO POR WORKERS DO MULTIPROCESSING
# ============================================================================
# Verifica√ß√£o se este √© o processo principal ou um worker do multiprocessing
# Processos workers criados por 'spawn' reimportam o m√≥dulo, mas n√£o devem
# executar a inicializa√ß√£o completa do projeto
_IS_MAIN_PROCESS = __name__ == '__main__' or not hasattr(sys.modules.get('__mp_main__', None), '__file__')

def _inicializar_ambiente():
    """
    Inicializa o ambiente do projeto (paths, .env, BERTScore workers).
    Esta fun√ß√£o s√≥ deve ser chamada no processo principal.
    """
    global MAX_WORKERS_ANALISE, PASTA_ENTRADA_RAIZ
    
    # Adiciona paths de utilit√°rios
    sys.path.extend(['./utils', './src', '../../src'])
    
    # Importa e carrega configura√ß√µes
    from util import UtilEnv
    UtilEnv.carregar_env('.env', pastas=['../', './'])
    
    # NOTA: BERTScore agora usa implementa√ß√£o simplificada com cache MD5 autom√°tico
    # N√£o √© mais necess√°rio configurar workers - a biblioteca bert_score gerencia internamente
    
    # L√™ vari√°veis de ambiente
    # BERTSCORE_DEVICE ainda √© utilizado pela nova implementa√ß√£o
    device_bert = UtilEnv.get_str('BERTSCORE_DEVICE', 'auto')
    
    MAX_WORKERS_ANALISE = UtilEnv.get_int('MAX_WORKERS_ANALISE', 10)
    PASTA_ENTRADA_RAIZ = os.getenv('PASTA_ENTRADA_RAIZ') or './saidas/'
    
    # Documenta configura√ß√µes (f-string apenas para documenta√ß√£o)
    f''' 
      CONSTANTES E CONFIGURA√á√ïES DE VARI√ÅVEIS DE AMBIENTE
      - `{MAX_WORKERS_ANALISE}`: n√∫mero m√°ximo de workers para an√°lise paralela
      - `{PASTA_ENTRADA_RAIZ}`: pasta ra√≠z de entrada dos espelhos
      - `{device_bert}`: dispositivo para BERTScore (cuda/cpu/auto)
    '''
    
    return MAX_WORKERS_ANALISE, PASTA_ENTRADA_RAIZ

# Valores padr√£o para quando importado por workers
MAX_WORKERS_ANALISE = 10
PASTA_ENTRADA_RAIZ = './saidas/'
'''
Compara com JsonAnalise os espelhos RAW, base e extra√ß√µes feitas pelos agentes.

FILOSOFIA DE SELE√á√ÉO DE M√âTRICAS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. BERTScore ‚Üí Textos longos com nuances sem√¢nticas
2. ROUGE-L   ‚Üí Estruturas/sequ√™ncias ordenadas
3. ROUGE-2   ‚Üí Frases m√©dias, precis√£o de bigramas
4. ROUGE-1   ‚Üí Termos individuais, palavras-chave (padr√£o para (estrutura))
5. Levenshtein ‚Üí Textos curtos exatos (nomes, IDs, valores num√©ricos)

RAZ√ïES:   
‚ú® BENEF√çCIO: Cada campo √© analisado pela m√©trica mais adequada ao seu tipo,
   gerando m√∫ltiplas perspectivas onde necess√°rio (ex: teseJuridica tem tanto
   sem√¢ntica profunda quanto precis√£o de fraseamento).
'''

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONSTANTES PADR√ÉO (reduz duplica√ß√£o nos cen√°rios)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ROTULO_ID_PADRAO = 'id'
CAMPOS_COMPARACAO_PADRAO = [
    'jurisprudenciaCitada', 'notas', 'informacoesComplementares', 
    'termosAuxiliares', 'teseJuridica', 'tema', 'referenciasLegislativas'
]

# Vari√°veis globais configuradas pelos cen√°rios
ORIGEM, DESTINOS, D_ROTULOS, CAMPOS_COMPARACAO, PASTA_SAIDA_COMPARACAO, ROTULO_ID, ROTULO_ORIGEM = None, None, None, None, None, None, None
TESTE = False

def ajustar_300_avaliacao_tcc():
    # carrega a lista do arquivo ./saidas/300tcc.txt
    # remove os arquivos de valia√ß√£o que n√£o est√£o na lista
    if not os.path.isfile('./saidas/300tcc.txt'):
        print('Arquivo 300tcc.txt n√£o encontrado')
        return
    print('Arquivo 300tcc.txt encontrado, filtrando...')
    with open('./saidas/300tcc.txt', 'r') as f:
        lista_300 = f.read().splitlines()
    q = 0
    for arquivo in os.listdir('./saidas/espelhos_base_gpt5_300/'):
        # o id do arquivo √© o nome do arquivo sem o path e sem a extens√£o .avaliacao.json
        id_peca = os.path.basename(arquivo).replace('.avaliacao.json', '').replace('.json', '')
        if id_peca not in lista_300:
            os.remove('./saidas/espelhos_base_gpt5_300/' + arquivo)
            print(f'Removido: {arquivo}')
            q += 1
    print(f'Mantidos apenas os arquivos de avalia√ß√£o dos 300 do TCC ({q} removidos)')

def base_raw():
    global ORIGEM, DESTINOS, D_ROTULOS, CAMPOS_COMPARACAO, PASTA_SAIDA_COMPARACAO, ROTULO_ID, ROTULO_ORIGEM
    ORIGEM = 'espelhos_raw/'
    DESTINOS = ['espelhos_base_gpt5/', 'espelhos_agentes_gpt5/', 'espelhos_base_gemma3_12b/', 'espelhos_agentes_gemma3_12b/', 'espelhos_base_gemma3_27b/', 'espelhos_agentes_gemma3_27b/']
    D_ROTULOS = ['base_gpt5','agentes_gpt5','base_gemma3(12)','agentes_gemma3(12)','base_gemma3(27)','agentes_gemma3(27)']
    ROTULO_ID = ROTULO_ID_PADRAO
    ROTULO_ORIGEM = 'RAW'
    CAMPOS_COMPARACAO = CAMPOS_COMPARACAO_PADRAO
    PASTA_SAIDA_COMPARACAO = 'analises_comparacao_raw/'
def base_gpt5():
    global ORIGEM, DESTINOS, D_ROTULOS, CAMPOS_COMPARACAO, PASTA_SAIDA_COMPARACAO, ROTULO_ID, ROTULO_ORIGEM
    ORIGEM = 'espelhos_base_gpt5/'
    DESTINOS = ['espelhos_agentes_gpt5/', 'espelhos_base_gemma3_12b/', 'espelhos_agentes_gemma3_12b/', 'espelhos_base_gemma3_27b/', 'espelhos_agentes_gemma3_27b/']
    D_ROTULOS = ['agentes_gpt5','base_gemma3(12)','agentes_gemma3(12)','base_gemma3(27)','agentes_gemma3(27)']
    ROTULO_ID = ROTULO_ID_PADRAO
    ROTULO_ORIGEM = 'base_gpt5'
    CAMPOS_COMPARACAO = CAMPOS_COMPARACAO_PADRAO
    PASTA_SAIDA_COMPARACAO = 'analises_comparacao_base_gpt5/'
def base_gpt5_300():
    base_gpt5()
    global ORIGEM, PASTA_SAIDA_COMPARACAO, TESTE, DESTINOS, D_ROTULOS
    #DESTINOS = ['espelhos_agentes_gpt5/', 'espelhos_base_gemma3_12b/', 'espelhos_base_gemma3_27b/']
    #D_ROTULOS = ['agentes_gpt5','base_gemma3(12)','base_gemma3(27)']
    ORIGEM = 'espelhos_base_gpt5_300/'
    PASTA_SAIDA_COMPARACAO = 'analises_comparacao_300/'
    TESTE = False # n√£o usa bertscore para teste r√°pido
    ajustar_300_avaliacao_tcc()
def base_gpt5_p():
    base_gpt5()
    global ORIGEM, PASTA_SAIDA_COMPARACAO, TESTE, DESTINOS, D_ROTULOS
    #DESTINOS = ['espelhos_agentes_gpt5/', 'espelhos_base_gemma3_12b/', 'espelhos_base_gemma3_27b/']
    #D_ROTULOS = ['agentes_gpt5','base_gemma3(12)','base_gemma3(27)']
    ORIGEM = 'espelhos_base_p/'
    PASTA_SAIDA_COMPARACAO = 'analises_comparacao_teste/'
    TESTE = True # n√£o usa bertscore para teste r√°pido
def base_gpt5_ag():
    base_gpt5_p()
    global ORIGEM
    ORIGEM = 'espelhos_agentes_p/'
def base_gpt5_g():
    base_gpt5_p()
    global ORIGEM, TESTE
    ORIGEM = 'espelhos_base_gpt5/'
    TESTE = True # n√£o usa bertscore para teste r√°pido
# Fun√ß√£o para inicializar cen√°rio padr√£o - chamada apenas no __main__
# base_gpt5() √© o cen√°rio padr√£o, mas s√≥ ser√° executado no processo principal

def _configurar_cenario():
    """Configura cen√°rio e valida pastas. Chamada apenas no processo principal."""
    global ORIGEM, DESTINOS, D_ROTULOS, CAMPOS_COMPARACAO, PASTA_SAIDA_COMPARACAO
    global ROTULO_ID, ROTULO_ORIGEM, TESTE, CONFIG_COMPARACAO
    
    # Seleciona cen√°rio padr√£o >>> Aqui pode ser alterado para testar cen√°rios menores e mais r√°pidos como o _p
    base_gpt5_300()
    
    # Valida configura√ß√£o
    assert len(DESTINOS) == len(D_ROTULOS), 'N√∫mero de destinos e r√≥tulos deve ser igual!'
    
    # Ajusta caminhos com PASTA_ENTRADA_RAIZ
    ORIGEM = os.path.join(PASTA_ENTRADA_RAIZ, ORIGEM)
    DESTINOS = [os.path.join(PASTA_ENTRADA_RAIZ, d) for d in DESTINOS]
    PASTA_SAIDA_COMPARACAO = os.path.join(PASTA_ENTRADA_RAIZ, PASTA_SAIDA_COMPARACAO)
    
    print('Pasta ra√≠z:', PASTA_ENTRADA_RAIZ)
    print('Origem:', ORIGEM)
    print('Destinos:', DESTINOS)
    print('Sa√≠da:', PASTA_SAIDA_COMPARACAO)
    
    assert os.path.isdir(ORIGEM), f'Pasta de origem "{ORIGEM}" n√£o existe!'
    for d in DESTINOS:
        assert os.path.isdir(d), f'Pasta de destinos "{d}" n√£o existe!'
    
    # Configura√ß√£o otimizada para nova estrutura JsonAnalise (sem metrica_global)
    CONFIG_COMPARACAO = {
        # N√≠vel de campos (1 = apenas raiz, 2 = raiz + 1 n√≠vel aninhado)
        'nivel_campos': 1,
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # CAMPOS COM M√öLTIPLAS M√âTRICAS (an√°lise multidimensional)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # BERTScore: similaridade sem√¢ntica profunda (textos longos)
        'campos_bertscore': [
            '(global)',                  # Vis√£o geral do documento
            'teseJuridica',              # Teses jur√≠dicas complexas + ROUGE-L (sem√¢ntica + precis√£o)
            'notas',                     # Textos descritivos (admite parafraseamento)
            'termosAuxiliares',          # Lista de termos t√©cnicos + ROUGE-2 (sem√¢ntica + bigramas)
            'informacoesComplementares'  # Informa√ß√µes adicionais (texto livre)
        ],
        
        # ROUGE-L: sequ√™ncias estruturadas (ordem importa)
        'campos_rouge': [
            '(global)',                   # Vis√£o geral do documento
            'jurisprudenciaCitada',       # Cita√ß√µes estruturadas + ROUGE-2 (estrutura + bigramas)
            'informacoesComplementares',  # Informa√ß√µes adicionais (texto livre)
            'referenciasLegislativas',    # Refer√™ncias legais (estrutura Lei/Art/¬ß)
            'notas',                     # Textos descritivos (admite parafraseamento)
            'teseJuridica',               # + BERTScore (valida fraseamento legal exato)
        ],
        
        # ROUGE-2: precision de bigramas (fraseamento t√©cnico e termos exatos)
        'campos_rouge2': [
            'termosAuxiliares',          # + BERTScore (bigramas t√©cnicos)
            'tema',                      # Temas como frases curtas
            'jurisprudenciaCitada',       # Cita√ß√µes estruturadas + ROUGE-2 (estrutura + bigramas)
            # (global) ser√° adicionado automaticamente aqui se n√£o estiver em outra m√©trica
        ],
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # OBSERVA√á√ÉO: (global) e (estrutura) recebem m√©tricas padr√£o autom√°ticas:
        # - (global) ‚Üí campos_rouge2 (se n√£o especificado em outra lista)
        # - (estrutura) ‚Üí campos_rouge1 (se n√£o especificado em outra lista)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # Configura√ß√µes de processamento
        'padronizar_simbolos': True,    # Normaliza aspas, espa√ßos, case
        'rouge_stemmer': True           # Usa stemmer no ROUGE para varia√ß√µes morfol√≥gicas
    }
    
    if TESTE:
        # Configura√ß√£o r√°pida para testes (sem BERTScore)
        from util import Util
        campos_bertscore = CONFIG_COMPARACAO.get('campos_bertscore', [])
        CONFIG_COMPARACAO['campos_bertscore'] = []
        CONFIG_COMPARACAO['campos_levenshtein'] = ['termosAuxiliares', 'referenciasLegislativas']
        campos_bertscore = [_ for _ in campos_bertscore if _ not in CONFIG_COMPARACAO['campos_rouge2']]
        _linha = '‚ö†Ô∏è  ' * 20
        print(f'\n{_linha}\nModo TESTE ativado: BERTScore desabilitado:\n - campos movidos para Rouge 2: {campos_bertscore}\n{_linha}\n')
        CONFIG_COMPARACAO['campos_rouge2'] += campos_bertscore
        Util.pausa(3)
    
    return CONFIG_COMPARACAO

# Vari√°vel global que ser√° inicializada no __main__
CONFIG_COMPARACAO = None


def _buscar_metricas_globais(stats):
    """
    Busca m√©tricas globais F1 nas estat√≠sticas, com fallback inteligente.
    
    Args:
        stats: DataFrame de estat√≠sticas do analisador
    
    Returns:
        DataFrame filtrado com m√©tricas globais F1, ou DataFrame vazio se n√£o encontrar
    """
    # Tenta ROUGE-2 primeiro (m√©trica padr√£o preferida)
    f1_global = stats[stats['metrica'] == '(global)_rouge2_F1']
    
    if len(f1_global) == 0:
        # Fallback: tenta qualquer (global)_*_F1
        f1_global = stats[stats['metrica'].str.contains(r'\(global\)_.*_F1', regex=True)]
    
    return f1_global


def processar_analise_estatistica(dados_analise, pasta_saida):
    """
    Executa a an√°lise estat√≠stica (LLM-as-a-Judge) usando a classe AnaliseEstatistica.
    """
    print("\nüìä Iniciando An√°lise Estat√≠stica (LLM-as-a-Judge)...")
    # Importa da nova localiza√ß√£o em src (j√° no path)
    try:
        from util_analise_estatistica import AnaliseEstatistica
    except ImportError:
        # Fallback se n√£o encontrar no path padr√£o, tenta adicionar ../src
        sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../src')))
        from util_analise_estatistica import AnaliseEstatistica
        
    import pandas as pd
    
    lista_dados = []
    
    # Lookups agora s√£o feitos via m√©todos do objeto dados_analise
    pk = dados_analise.config.nome_campo_id

    # Defini√ß√£o EXPLICITA dos pares para an√°lise (Base vs Agentes da mesma fam√≠lia)
    # Tuplas: (Nome Fam√≠lia/Relat√≥rio, R√≥tulo Base, R√≥tulo Agente)
    PARES_ANALISE = [
        ('GPT-5',            'base_gpt5',        'agentes_gpt5'),
        ('Gemma 3 12b',      'base_gemma3(12)',  'agentes_gemma3(12)'),
        ('Gemma 3 27b',      'base_gemma3(27)',  'agentes_gemma3(27)')
    ]
    
    # Iterar sobre cada PAR definido
    for nome_familia, rotulo_base, rotulo_agente in PARES_ANALISE:
        print(f"   Processando fam√≠lia: {nome_familia} ({rotulo_base} vs {rotulo_agente})...")
        
        # Verifica se os r√≥tulos existem nos dados
        if rotulo_base not in dados_analise.rotulos or rotulo_agente not in dados_analise.rotulos:
            print(f"      ‚ö†Ô∏è  Saltando {nome_familia}: r√≥tulos n√£o encontrados nos dados.")
            continue

        # Para cada pe√ßa carregada
        for item in dados_analise.dados:
            id_peca = item.get(pk)
            if not id_peca: continue
            
            # Busca dados nos lookups
            tokens = dados_analise.get_tokens(id_peca)
            evals = dados_analise.get_avaliacao(id_peca)
            
            # Extrai valores usando os r√≥tulos do PAR
            v1 = evals.get(f'{rotulo_base}_F1')
            v2 = evals.get(f'{rotulo_agente}_F1')
            
            # Custo (Tokens Total)
            c1 = tokens.get(f'{rotulo_base}_total', 0)
            c2 = tokens.get(f'{rotulo_agente}_total', 0)
            
            # Fallback para evitar divis√£o por zero
            if c1 == 0: c1 = 1 
            if c2 == 0: c2 = 1

            # S√≥ adiciona se tiver avalia√ß√£o em ambos
            if v1 is not None and v2 is not None:
                lista_dados.append({
                    'valor1': v1, # Base (F1)
                    'valor2': v2, # Agente (F1)
                    'custo1': c1, # Base (Tokens)
                    'custo2': c2, # Agente (Tokens)
                    'familia': nome_familia
                })
    
    if not lista_dados:
        print("‚ùå Nenhum dado de avalia√ß√£o (LLM-as-a-Judge) encontrado para an√°lise estat√≠stica.")
        return
        
    print(f"   Total de pares recuperados: {len(lista_dados)}")
    df_stat = pd.DataFrame(lista_dados)
    
    # Configura an√°lise com r√≥tulos gen√©ricos pois agora estamos agrupando corretamente
    analise = AnaliseEstatistica(df_stat, config={
        'rotulo1': 'Base',   # Gen√©rico
        'rotulo2': 'Agente', # Gen√©rico
        'arquivo_saida': os.path.join(pasta_saida, 'relatorio_analise_estatistica.md')
    })
    analise.processar_analise()
    analise.salvar_relatorio()
    print("\n‚úÖ An√°lise Estat√≠stica conclu√≠da.")


if __name__ == '__main__':
    ''' realiza a compara√ß√£o das extra√ß√µes dos espelhos na pasta ORIGEM com as extra√ß√µes nas pastas DESTINOS
        todas as pastas devem conter arquivos json nomeados com o id_peca.json, outros arquivos s√£o ignorados
        caso o arquivo n√£o exista em uma das pastas, √© registrado como "Inexistente"
        caso exista uma chave "erro" no json, √© registrado como "Erro na extra√ß√£o"
        caso o campo origem seja nulo ou vazio e no destino tamb√©m, os campos podem ser removidos na compara√ß√£o
        o resultado √© salvo conforme exemplo no arquivo "exemplo_dataframe.py"
    '''
    
    # =========================================================================
    # INICIALIZA√á√ÉO DO AMBIENTE (APENAS NO PROCESSO PRINCIPAL)
    # =========================================================================
    # Isso evita que os workers do multiprocessing reimportem as configura√ß√µes
    
    # 1. Inicializa ambiente (paths, .env, BERTScore workers)
    MAX_WORKERS_ANALISE, PASTA_ENTRADA_RAIZ = _inicializar_ambiente()
    
    # 2. Imports pesados - s√≥ ap√≥s inicializa√ß√£o e apenas no processo principal
    from util_json import JsonAnaliseDataFrame
    from util_json_carga import CargaDadosComparacao
    
    # 3. Configura cen√°rio (valida pastas, carrega CONFIG_COMPARACAO)
    CONFIG_COMPARACAO = _configurar_cenario()
    
    # =========================================================================
    # EXECU√á√ÉO PRINCIPAL
    # =========================================================================
    
    print("=" * 80)
    print("üîç COMPARA√á√ÉO DE EXTRA√á√ïES - Espelhos RAW vs Base vs Agentes")
    print("=" * 80)
    
    # tipo de arquivo \d{12}.\d+.\d*.json (padr√£o)
    RE_ARQUIVOS_JSON_PADRAO = re.compile(r'^(\d{12})\.\d+\.\d*\.json$')
    
        # Instancia a classe de carga de dados
    carga = CargaDadosComparacao(
        pasta_origem=ORIGEM,
        pastas_destinos=DESTINOS,
        rotulo_id=ROTULO_ID,
        rotulo_origem=ROTULO_ORIGEM,
        rotulos_destinos=D_ROTULOS,
        campos_comparacao=CAMPOS_COMPARACAO,
        regex_arquivos=RE_ARQUIVOS_JSON_PADRAO
    )
    
    # Carrega os dados - agora retorna JsonAnaliseDados completo
    dados_analise = carga.carregar()
    
    # Exibe resumo dos dados
    print(dados_analise.resumo())

    if not dados_analise.dados:
        print("\n‚ùå Nenhum dado encontrado para compara√ß√£o!")
        sys.exit(1)
    
    SO_ANALISE_ESTATISTICA = False # Configurar conforme necessidade
    
    if SO_ANALISE_ESTATISTICA:
        processar_analise_estatistica(dados_analise, PASTA_SAIDA_COMPARACAO)
        sys.exit(0)

    print(f"\n‚öôÔ∏è  Configura√ß√£o de compara√ß√£o:")
    print(f"   Campos analisados: {len(CAMPOS_COMPARACAO)}")
    print(f"   N√≠vel de campos: {CONFIG_COMPARACAO.get('nivel_campos')}")
    print(f"   Campos BERTScore: {len(CONFIG_COMPARACAO.get('campos_bertscore', []))} ‚Üí {CONFIG_COMPARACAO.get('campos_bertscore', [])}")
    print(f"   Campos ROUGE-L: {len(CONFIG_COMPARACAO.get('campos_rouge', []))} ‚Üí {CONFIG_COMPARACAO.get('campos_rouge', [])}")
    print(f"   Campos ROUGE-1: {len(CONFIG_COMPARACAO.get('campos_rouge1', []))} ‚Üí {CONFIG_COMPARACAO.get('campos_rouge1', [])}")
    print(f"   Campos ROUGE-2: {len(CONFIG_COMPARACAO.get('campos_rouge2', []))} ‚Üí {CONFIG_COMPARACAO.get('campos_rouge2', [])} (+ (global) autom√°tico)")
    print(f"   üìå Nota: (estrutura) ser√° adicionado automaticamente em ROUGE-1")

    # Cria analisador
    print(f"\nüöÄ Iniciando an√°lise com JsonAnaliseDataFrame...")
    analisador = JsonAnaliseDataFrame(
        dados_analise,  # Nova interface: passa JsonAnaliseDados
        config=CONFIG_COMPARACAO,
        pasta_analises=PASTA_SAIDA_COMPARACAO,
        max_workers=MAX_WORKERS_ANALISE,
        incluir_valores_analise=True,  # incluir valores nos JSONs de an√°lise
        gerar_exemplos_md=True,  # Gera arquivo Markdown com exemplos
        max_exemplos_md_por_metrica=5,  # M√°ximo de 5 exemplos por m√©trica
        gerar_relatorio=True  # Gera relat√≥rio markdown
    )
    
    # Configura informa√ß√µes do relat√≥rio
    if analisador.relatorio:
        titulo_experimento = f"Compara√ß√£o {ROTULO_ORIGEM} vs Modelos"
        descricao_experimento = f"An√°lise comparativa de extra√ß√µes JSON usando m√∫ltiplas m√©tricas (BERTScore, ROUGE, Levenshtein)"
        analisador.relatorio.set_overview(
            titulo=titulo_experimento,
            descricao=descricao_experimento,
            rotulos=analisador.rotulos,
            total_documentos=len(dados_analise.dados),
            campos_comparacao=CAMPOS_COMPARACAO
        )
        analisador.relatorio.set_config(CONFIG_COMPARACAO, CAMPOS_COMPARACAO)

    # Define nome base dos arquivos (usado pelos m√©todos de exporta√ß√£o)
    nome_arquivo_base = 'comparacao_extracoes'
    arquivo_excel = os.path.join(PASTA_SAIDA_COMPARACAO, f'{nome_arquivo_base}.xlsx')

    SO_GRAFICOS = False  # Define como True para gerar apenas gr√°ficos de Excel existente
    if SO_GRAFICOS:
       # Apenas atualiza os gr√°ficos do excel j√° existente 
        if os.path.isfile(arquivo_excel):
            print(f"\n‚ö†Ô∏è  Aviso: O arquivo Excel de compara√ß√£o j√° existe: {arquivo_excel}\nGerando gr√°ficos...")
            analisador.gerar_graficos_de_excel(arquivo_excel, pasta_saida=PASTA_SAIDA_COMPARACAO)
            exit(0)
    
    SO_LLM_AS_A_JUDGE = False  # Define como True para usar LLM as a Judge
    if SO_LLM_AS_A_JUDGE:
        # Apenas atualiza as an√°lises de LLM as a Judge do Excel existente
        if os.path.isfile(arquivo_excel):
            print(f"\n‚ö†Ô∏è  Aviso: O arquivo Excel de compara√ß√£o j√° existe: {arquivo_excel}\nAtualizando com an√°lises de LLM as a Judge...")
            # Atualiza apenas a aba de avalia√ß√£o LLM
            analisador.atualizar_avaliacao_llm_no_excel(arquivo_excel, gerar_graficos=True)
            print(f"\n‚úÖ Aba 'Avalia√ß√£o LLM' atualizada com sucesso!")
            print(f"üìÅ Arquivo: {arquivo_excel}")
            exit(0)
        else:
            print(f"\n‚ùå Erro: Arquivo Excel n√£o encontrado: {arquivo_excel}")
            print(f"   Execute primeiro sem SO_LLM_AS_A_JUDGE=True para gerar o arquivo base.")
            exit(1)
    
    # Gera DataFrame
    print("üìä Gerando DataFrame...")
    df = analisador.to_df()
    
    print(f"\n‚úÖ An√°lise conclu√≠da!")
    print(f"   Documentos processados: {len(df)}")
    print(f"   Colunas geradas: {len(df.columns)}")
    
    # Mostra estat√≠sticas globais
    print("\nüìà Estat√≠sticas Globais:")
    stats = analisador.estatisticas_globais()
    
    # NOVA ESTRUTURA: M√∫ltiplas t√©cnicas para (global)
    # Exemplos: (global)_rouge2_F1, (global)_rouge1_F1, etc.
    print("\n   üìä F1-Score por T√©cnica (campo global):")
    
    # Agrupa por t√©cnica
    tecnicas_disponiveis = stats['tecnica'].unique()
    for tecnica in sorted(tecnicas_disponiveis):
        # Busca F1 global dessa t√©cnica
        metrica_busca = f'(global)_{tecnica.lower().replace("-", "")}_F1'
        f1_tecnica = stats[stats['metrica'] == metrica_busca]
        
        if len(f1_tecnica) > 0:
            print(f"\n   {tecnica}:")
            for _, row in f1_tecnica.iterrows():
                print(f"      {row['modelo']:15s}: Mean={row['mean']:.4f}, Median={row['median']:.4f}, Std={row['std']:.4f}")
    
    # Busca m√©tricas globais usando fun√ß√£o auxiliar
    f1_global = _buscar_metricas_globais(stats)
    
    # Mostra compara√ß√£o de modelos (usa m√©trica dispon√≠vel)
    if len(f1_global) > 0:
        metrica_comparacao = f1_global.iloc[0]['metrica']
        print(f"\nüîç Compara√ß√£o por documento (m√©trica: {metrica_comparacao}):")
        try:
            comp_f1 = analisador.comparar_modelos(metrica_comparacao)
            print(comp_f1.head(10).to_string(index=False))
        except ValueError as e:
            print(f"\n   ‚ö†Ô∏è  Erro ao comparar modelos: {e}")
    else:
        print("\n   ‚ö†Ô∏è  Nenhuma m√©trica global F1 dispon√≠vel para compara√ß√£o")
    
    # Exporta resultados
    print("\nüíæ Exportando resultados...")
    
    # CSV (m√©todo retorna o caminho do arquivo gerado)
    arquivo_csv = analisador.exportar_csv(nome_arquivo_base)
    arquivo_estatisticas = arquivo_csv.replace('.csv', '.estatisticas.csv')
    print(f"   ‚úì CSV: {arquivo_csv}")
    print(f"   ‚úì Estat√≠sticas CSV: {arquivo_estatisticas}")
    
    # Excel com formata√ß√£o avan√ßada (mapas de calor)
    print("\n   Gerando Excel formatado com mapas de calor...")
    arquivo_excel = analisador.exportar_excel(
        nome_arquivo_base,  # M√©todo adiciona .xlsx automaticamente
        incluir_estatisticas=True,
        usar_formatacao_avancada=True,  # Usa UtilPandasExcel com mapas de calor
        congelar_paineis=True,
        gerar_graficos=True  # Gr√°ficos gerados separadamente
    )
    print(f"   ‚úì Excel formatado: {arquivo_excel}")
    print(f"      ‚Ä¢ Aba 'Resultados': m√©tricas por documento com mapa de calor")
    print(f"      ‚Ä¢ Aba 'Estat√≠sticas': agrega√ß√µes globais")
    print(f"      ‚Ä¢ Aba 'Compara√ß√£o_F1': compara√ß√£o de modelos")
    
    # Resumo final
    print("\nüìä Resumo Final:")
    print(f"   Total de campos comparados: {len(CAMPOS_COMPARACAO)}")
    print(f"   Campos: {', '.join(CAMPOS_COMPARACAO[:3])}...")
    
    # Melhor modelo por F1 (reutiliza f1_global j√° calculado)
    if len(f1_global) > 0:
        idx_vencedor = f1_global['mean'].idxmax()
        modelo_vencedor = f1_global.loc[idx_vencedor, 'modelo']
        f1_vencedor = f1_global.loc[idx_vencedor, 'mean']
        metrica_vencedor = f1_global.iloc[0]['metrica']
        print(f"\nüèÜ Melhor modelo ({metrica_vencedor}): {modelo_vencedor} (Mean={f1_vencedor:.4f})")
        
        # Mostra todas as m√©tricas globais do vencedor (reutiliza padr√£o de busca)
        print(f"\n   Todas as m√©tricas do modelo vencedor ({modelo_vencedor}):")
        stats_vencedor = stats[(stats['modelo'] == modelo_vencedor) & (stats['metrica'].str.contains(r'\(global\)_.*_F1', regex=True))]
        for _, row in stats_vencedor.iterrows():
            tecnica = row['tecnica']
            print(f"      {tecnica:12s} F1: Mean={row['mean']:.4f}, Median={row['median']:.4f}, Std={row['std']:.4f}")
    else:
        print("\n   ‚ö†Ô∏è  Estat√≠sticas n√£o dispon√≠veis para exibir vencedor")
    

    # Gera estat√≠stica tamb√©m se n√£o for s√≥ estat√≠stica (j√° que se fosse True teria sa√≠do antes)
    processar_analise_estatistica(dados_analise, PASTA_SAIDA_COMPARACAO)

    print("\n" + "=" * 80)
    print("‚úÖ Compara√ß√£o conclu√≠da com sucesso!")
    print(f"üìÅ Resultados salvos em: {PASTA_SAIDA_COMPARACAO}")
    print("=" * 80)


